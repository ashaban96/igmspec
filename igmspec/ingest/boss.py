""" Module to ingest SDSS III (aka BOSS) data products
"""
from __future__ import print_function, absolute_import, division, unicode_literals


import numpy as np
import os, json
import pdb
import datetime

from astropy.table import Table, Column, vstack
from astropy.time import Time
from astropy.io import fits
from astropy.coordinates import SkyCoord, match_coordinates_sky
from astropy import units as u

from linetools import utils as ltu
from linetools.spectra import io as lsio

from specdb.build.utils import chk_for_duplicates
from specdb.build.utils import chk_meta
from specdb.build.utils import init_data


def grab_meta():
    """ Grab BOSS meta Table

    Returns
    -------
    boss_meta : Table

    """

    #http://www.sdss.org/dr12/algorithms/boss-dr12-quasar-catalog/
    boss_dr12 = Table.read(os.getenv('RAW_IGMSPEC')+'/BOSS/DR12Q.fits.gz')
    boss_dr12['CAT'] = ['DR12Q']*len(boss_dr12)
    gd = np.any([boss_dr12['Z_PIPE'] > 0., boss_dr12['Z_PCA'] > 0.],axis=0) # CUTS Z_VI
    boss_dr12 = boss_dr12[gd]
    #
    boss_sup = Table.read(os.getenv('RAW_IGMSPEC')+'/BOSS/DR12Q_sup.fits.gz')
    boss_sup['CAT'] = ['SUPGD']*len(boss_sup)
    boss_supbad = Table.read(os.getenv('RAW_IGMSPEC')+'/BOSS/DR12Q_supbad.fits.gz')
    boss_supbad['CAT'] = ['SUPBD']*len(boss_supbad)
    # Collate
    boss_meta = vstack([boss_dr12, boss_sup, boss_supbad], join_type='outer')
    #
    nboss = len(boss_meta)
    # DATE-OBS
    t = Time(list(boss_meta['MJD'].data), format='mjd', out_subfmt='date')  # Fixes to YYYY-MM-DD
    boss_meta.add_column(Column(t.iso, name='DATE-OBS'))
    # Add columns
    boss_meta.add_column(Column(['BOSS']*nboss, name='INSTR'))
    boss_meta.add_column(Column(['BOTH']*nboss, name='GRATING'))
    #http://www.sdss.org/instruments/boss_spectrograph/
    boss_meta.add_column(Column([2100.]*nboss, name='R'))  # RESOLUTION
    boss_meta.add_column(Column(['SDSS 2.5-M']*nboss, name='TELESCOPE'))
    # Redshift logic
    boss_meta['zem_GROUP'] = boss_meta['Z_PCA']
    boss_meta['sig_zem'] = boss_meta['ERR_ZPCA']
    boss_meta['flag_zem'] = [str('BOSS_PCA ')]*nboss
    # Fix bad redshifts
    bad_pca = boss_meta['Z_PCA'] < 0.
    boss_meta['zem_GROUP'][bad_pca] = boss_meta['Z_PIPE'][bad_pca]
    boss_meta['sig_zem'][bad_pca] = boss_meta['ERR_ZPIPE'][bad_pca]
    boss_meta['flag_zem'][bad_pca] = str('BOSS_PIPE')
    # Rename RA/DEC
    boss_meta.rename_column('RA', 'RA_GROUP')
    boss_meta.rename_column('DEC', 'DEC_GROUP')
    # STYPE
    boss_meta['STYPE'] = [str('QSO')]*len(boss_meta)
    # Check
    assert chk_meta(boss_meta, chk_cat_only=True)
    # Return
    return boss_meta

'''
def meta_for_build():
    """ Load the meta info
    DR12 quasars : https://data.sdss.org/datamodel/files/BOSS_QSO/DR12Q/DR12Q.html

    Returns
    -------

    """
    boss_meta = grab_meta()
    # Cut down to unique
    c_main = SkyCoord(ra=boss_meta['RA_SPEC'], dec=boss_meta['DEC_SPEC'], unit='deg')
    idx, d2d, d3d = match_coordinates_sky(c_main, c_main, nthneighbor=2)
    dups = np.where(d2d < 2*u.arcsec)[0]
    flgs = np.array([True]*len(boss_meta))
    #
    for ii in dups:
        if boss_meta[ii]['CAT'] == 'SUPBD':
            flgs[ii] = False
    boss_meta = boss_meta[flgs]
    if not chk_for_duplicates(boss_meta):
        raise ValueError("DUPLICATES IN BOSS")
    #
    meta = Table()
    for key in ['RA', 'DEC', 'zem', 'sig_zem', 'flag_zem']:
        meta[key] = boss_meta[key]
    meta['STYPE'] = [str('QSO')]*len(meta)
    # Return
    return meta
'''


def get_specfil(row, KG=False, hiz=False):
    """Grab the BOSS file name + path
    KG : bool, optional
      Grab MFR continuum generated by KG
    """
    pnm = '{0:04d}'.format(row['PLATE'])
    fnm = '{0:04d}'.format(row['FIBERID'])
    mjd = str(row['MJD'])
    # KG?
    if KG:
        path = os.getenv('RAW_IGMSPEC')+'/BOSS/BOSSLyaDR12_spectra_v1.0/{:s}/'.format(pnm)
        specfil = path+'speclya-{:04d}-{:d}-{:04d}.fits.gz'.format(row['PLATE'], row['MJD'], row['FIBERID'])
        return specfil

    # Generate file name (DR4 is different)
    path = os.getenv('RAW_IGMSPEC')+'/BOSS/'
    #
    if hiz:
        path += 'hiz/'
    elif row['CAT'] == 'SUPGD':
        path += 'Sup12/'
    elif row['CAT'] == 'SUPBD':
        path += 'SupBad/'
        #specfil = path+'spec-{:04d}-{:d}-{:04d}.fits.gz'.format(row['PLATE'], row['MJD'], row['FIBERID'])
    elif row['CAT'] == 'DR12Q':
        path += 'DR12Q/'
    else:
        raise ValueError("Uh oh")
    specfil = path+'spec-{:04d}-{:d}-{:04d}.fits.gz'.format(row['PLATE'], row['MJD'], row['FIBERID'])
    # Finish
    return specfil


def hdf5_adddata(hdf, sname, meta, debug=False, chk_meta_only=False, boss_hdf=None, **kwargs):
    """ Add BOSS data to the DB

    Parameters
    ----------
    hdf : hdf5 pointer
    IDs : ndarray
      int array of IGM_ID values in mainDB
    sname : str
      Survey name
    chk_meta_only : bool, optional
      Only check meta file;  will not write
    boss_hdf : str, optional


    Returns
    -------

    """
    # Add Survey
    print("Adding {:s} survey to DB".format(sname))
    if boss_hdf is not None:
        print("Using previously generated {:s} dataset...".format(sname))
        boss_hdf.copy(sname, hdf)
        return
    boss_grp = hdf.create_group(sname)

    # Build spectra (and parse for meta)
    nspec = len(meta)
    max_npix = 4650  # Just needs to be large enough
    data = init_data(max_npix, include_co=True)
    # Init
    spec_set = hdf[sname].create_dataset('spec', data=data, chunks=True,
                                         maxshape=(None,), compression='gzip')
    spec_set.resize((nspec,))
    wvminlist = []
    wvmaxlist = []
    speclist = []
    npixlist = []
    # Loop
    maxpix = 0
    for jj,row in enumerate(meta):
        # Generate full file
        full_file = get_specfil(row)
        if full_file == 'None':
            continue
        # Read
        spec = lsio.readspec(full_file)
        # npix
        npix = spec.npix
        # Kludge for higest redshift systems
        if npix < 10:
            full_file = get_specfil(row, hiz=True)
            try:
                spec = lsio.readspec(full_file)
            except:
                print("Missing: {:s}".format(full_file))
            npix = spec.npix
        elif npix > max_npix:
            raise ValueError("Not enough pixels in the data... ({:d})".format(npix))
        else:
            maxpix = max(npix,maxpix)
        # Parse name
        fname = full_file.split('/')[-1]
        # Fill
        for key in ['wave','flux','sig']:
            data[key] = 0.  # Important to init (for compression too)
        data['flux'][0][:npix] = spec.flux.value
        data['sig'][0][:npix] = spec.sig.value
        data['wave'][0][:npix] = spec.wavelength.value
        # GZ Continuum -- packed in with spectrum, generated by my IDL script
        try:
            co = spec.co.value
        except AttributeError:
            co = np.zeros_like(spec.flux.value)
        # KG Continuum
        KG_file = get_specfil(row, KG=True)
        if os.path.isfile(KG_file) and (npix>1):  # Latter is for junk in GZ file.  Needs fixing
            hduKG = fits.open(KG_file)
            KGtbl = hduKG[1].data
            wvKG = 10.**KGtbl['LOGLAM']
            try:
                assert (wvKG[0]-spec.wavelength[0].value) < 1e-5
            except:
                pdb.set_trace()
            gdpix = np.where(wvKG < (1+row['zem_GROUP'])*1200.)[0]
            co[gdpix] = KGtbl['CONT'][gdpix]
        data['co'][0][:npix] = co
        # Meta
        speclist.append(str(fname))
        wvminlist.append(np.min(data['wave'][0][:npix]))
        wvmaxlist.append(np.max(data['wave'][0][:npix]))
        npixlist.append(npix)
        if chk_meta_only:
            continue
        # Only way to set the dataset correctly
        spec_set[jj] = data

    #
    print("Max pix = {:d}".format(maxpix))
    # Add columns
    meta.add_column(Column(speclist, name='SPEC_FILE'))
    meta.add_column(Column(npixlist, name='NPIX'))
    meta.add_column(Column(wvminlist, name='WV_MIN'))
    meta.add_column(Column(wvmaxlist, name='WV_MAX'))
    meta.add_column(Column(np.arange(nspec,dtype=int),name='GROUP_ID'))
    meta.add_column(Column([2000.]*len(meta), name='EPOCH'))

    # Add HDLLS meta to hdf5
    if chk_meta(meta):
        if chk_meta_only:
            pdb.set_trace()
        hdf[sname]['meta'] = meta
    else:
        pdb.set_trace()
        raise ValueError("meta file failed")
    # References
    refs = [dict(url='http://adsabs.harvard.edu/abs/2015ApJS..219...12A',
                 bib='boss_qso_dr12'),
            ]
    jrefs = ltu.jsonify(refs)
    hdf[sname]['meta'].attrs['Refs'] = json.dumps(jrefs)
    #
    return

def add_coflag(hdf):
    """ Generate a continuum flag to add to the meta table
    Parameters
    ----------
    hdf

    Returns
    -------
    new_meta : Table
      New column 'flag_co' which is a bitwise flag
        1 : GZ
        2 : KG

    """
    dir = os.getenv('RAW_IGMSPEC')
    # Load meta
    meta = Table(hdf['BOSS_DR12']['meta'].value)
    nspec = len(meta)
    flg_co = np.zeros(nspec).astype(int)

    # Loop on chunks of 10000 spectra
    chunk = 10000
    nsub = 0
    while(nsub < nspec):
        idx = np.arange(nsub,min(nsub+chunk, nspec)).astype(int)
        # Grab spectra
        msk = np.array([False]*nspec)
        msk[idx] = True
        data = hdf['BOSS_DR12']['spec'][msk]

        # Add GZ flag
        zem = meta['zem_GROUP'][idx]
        # Avoid KG region
        wvlya = 1215.67*(1+zem)
        wvarr = np.outer(wvlya, np.ones(data['wave'].shape[1]))
        gdwv = wvarr > data['wave']
        # Check co
        gdco = data['co'] > 0.
        gdarr = gdwv & gdco
        # Finish
        gd_GZ = np.sum(gdarr,axis=1) > 0
        flg_co[idx[gd_GZ]] += 1

        # KG -- Loop on rows
        plates = meta['PLATE'][idx].data
        fibers = meta['FIBERID'][idx].data
        mjds = meta['MJD'][idx].data
        for ii in range(len(idx)):
            pnm = '{0:04d}'.format(plates[ii])
            path = dir+'/BOSS/BOSSLyaDR12_spectra_v1.0/{:s}/'.format(pnm)
            specfil = path+'speclya-{:04d}-{:d}-{:04d}.fits.gz'.format(plates[ii], mjds[ii], fibers[ii])
            if os.path.isfile(specfil):
                flg_co[idx[ii]] += 2
        nsub = min(nsub+chunk, nspec)
        pdb.set_trace()
    # Finish
    meta['flag_co'] = flg_co
    return meta


def add_ssa(hdf, dset):
    """  Add SSA info to meta dataset
    Parameters
    ----------
    hdf
    dset : str
    """
    from specdb.ssa import default_fields
    Title = '{:s}: BOSS DR12 Quasars'.format(dset)
    ssa_dict = default_fields(Title, flux='flambda', fxcalib='ABSOLUTE')
    hdf[dset]['meta'].attrs['SSA'] = json.dumps(ltu.jsonify(ssa_dict))
